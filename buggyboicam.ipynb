{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import monai\n",
    "import numpy as np\n",
    "import torch\n",
    "import medmnist\n",
    "from acsconv.converters import ACSConverter\n",
    "from torch import Tensor\n",
    "\n",
    "from create_dataloader import make_dataloaders\n",
    "from medcam import medcam\n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "from model_picker import ModelType, get_model\n",
    "from plot_image import plot_image\n",
    "\n",
    "from experiments.MedMNIST3D.models import ResNet18, ResNet50\n",
    "from experiments.MedMNIST3D.utils import Transform3D, model_to_syncbn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "MODELS_ROOT = \"./models\"\n",
    "DATA_PATH = \"./datasets/sorted_downscaled\"\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "model_type: ModelType = ModelType.ResNet18\n",
    "scale: float = 0.25\n",
    "assert scale in [0.25, 0.5, 1.0]\n",
    "\n",
    "\n",
    "model_path = f\"{MODELS_ROOT}/{model_type.name}_{str(int(scale*100)).zfill(3)}.pth\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "_, _, test_loader = make_dataloaders(num_workers=0, persistent_workers=False, data_path=DATA_PATH, batch_size=BATCH_SIZE, scale=scale)\n",
    "num_classes = len(test_loader.dataset.get_image_classes())\n",
    "\n",
    "model = get_model(model_type)\n",
    "model = model_to_syncbn(ACSConverter(model))\n",
    "model.to(device)\n",
    "model = medcam.inject(model, output_dir=\"attention_maps\", save_maps=True, return_attention=True, layer=\"auto\")\n",
    "model.load_state_dict(torch.load(model_path, map_location=device)['net'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_volume(attention_map):\n",
    "\tX, Y, Z = np.mgrid[0:28, 0:28, 0:28]\n",
    "\tvalues = attention_map\n",
    "\n",
    "\tfig = go.Figure(data=go.Volume(\n",
    "\t\tx=X.flatten(),\n",
    "\t\ty=Y.flatten(),\n",
    "\t\tz=Z.flatten(),\n",
    "\t\tvalue=values.flatten(),\n",
    "\t\tisomin=-0.1,\n",
    "\t\tisomax=0.8,\n",
    "\t\topacity=0.1,  # needs to be small to see through all surfaces\n",
    "\t\tsurface_count=21,  # needs to be a large number for good volume rendering\n",
    "\t\tcolorscale='RdBu'\n",
    "\t))\n",
    "\tfig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from monai.data.nifti_writer import nib\n",
    "\n",
    "image_batch, batch_labels = next(test_loader.__iter__())\n",
    "model.eval()\n",
    "\n",
    "predictions, attention_maps = model(image_batch.to(device))\n",
    "\n",
    "for id, image in enumerate(image_batch):\n",
    "    first_channel: Tensor = image[0].cpu().numpy()\n",
    "    first_channel_dot_nii = nib.Nifti1Image(first_channel, affine=np.eye(4))\n",
    "    nib.save(first_channel_dot_nii, f\"attention_maps/image{id}\" + \".nii\")\n",
    "    plot_volume(first_channel)\n",
    "\n",
    "for id, attention_map in enumerate(attention_maps):\n",
    "    first_channel: Tensor = attention_map[0].cpu().numpy()\n",
    "    first_channel_dot_nii = nib.Nifti1Image(first_channel, affine=np.eye(4))\n",
    "    nib.save(first_channel_dot_nii, f\"attention_maps/attention_map_{id}\" + \".nii\")\n",
    "    plot_volume(first_channel)\n",
    "\n",
    "print(\"I'm done, just so you know\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
