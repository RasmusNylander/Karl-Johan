{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from create_dataloader import make_dataloaders\n",
    "from medcam import medcam\n",
    "\n",
    "from model_picker import ModelType, get_model\n",
    "from monai.data.nifti_writer import nib\n",
    "from tqdm import trange"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODELS_ROOT = \"./models\"\n",
    "DATA_PATH = \"./datasets/sorted_downscaled\"\n",
    "BATCH_SIZE = 1\n",
    "assert BATCH_SIZE == 1\n",
    "\n",
    "model_type: ModelType = ModelType.ResNet18\n",
    "scale: float = 0.5\n",
    "assert scale in [0.25, 0.5, 1.0]\n",
    "\n",
    "model_string_id = f\"{model_type.name}_{str(int(scale*100)).zfill(3)}\"\n",
    "\n",
    "model_path = f\"{MODELS_ROOT}/{model_string_id}.pth\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "_, _, test_loader = make_dataloaders(num_workers=0, persistent_workers=False, data_path=DATA_PATH, batch_size=BATCH_SIZE, scale=scale)\n",
    "num_classes = len(test_loader.dataset.get_image_classes())\n",
    "\n",
    "model = get_model(model_type)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device)['net'], strict=True)\n",
    "model = medcam.inject(model, return_attention=True, layer=\"auto\", label=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_volume(attention_map, image):\n",
    "    X, Y, Z = np.mgrid[0:(256*scale), 0:(128*scale), 0:(128*scale)]\n",
    "    image_values = image\n",
    "    attention_values = attention_map\n",
    "    # attention_values[attention_map < .5] = 0\n",
    "    attention_volume = go.Volume(\n",
    "        x=X.flatten(),\n",
    "        y=Y.flatten(),\n",
    "        z=Z.flatten(),\n",
    "        value=attention_values.flatten(),\n",
    "        isomin=0.0,\n",
    "        isomax=1.0,\n",
    "        opacity=0.05,  # needs to be small to see through all surfaces\n",
    "        surface_count=21,  # needs to be a large number for good volume rendering\n",
    "        colorscale='RdBu_r'\n",
    "    )\n",
    "    print(f\"Image size: {image_values.shape} Attention map size: {attention_values.shape}\")\n",
    "    image_volume = go.Volume(\n",
    "        x=X.flatten(),\n",
    "        y=Y.flatten(),\n",
    "        z=Z.flatten(),\n",
    "        value=image_values.flatten(),\n",
    "        isomin=0.0,\n",
    "        isomax=255.0,\n",
    "        opacity=0.1,  # needs to be small to see through all surfaces\n",
    "        surface_count=21,  # needs to be a large number for good volume rendering\n",
    "        colorscale='greys'\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=(image_volume, attention_volume))\n",
    "    # fig = go.Figure(data=attention_volume)\n",
    "\n",
    "    fig.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_batch, batch_labels = next(test_loader.__iter__())\n",
    "model.eval()\n",
    "\n",
    "predictions, attention_maps = model(image_batch.to(device))\n",
    "\n",
    "\n",
    "for id, image in enumerate(image_batch):\n",
    "    first_channel: Tensor = image[0].cpu().numpy()\n",
    "\n",
    "for id, attention_map in enumerate(attention_maps):\n",
    "    first_channel: Tensor = attention_map[0].cpu().numpy()\n",
    "    plot_volume(first_channel, image_batch[0][0])\n",
    "\n",
    "print(\"I'm done, just so you know\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
