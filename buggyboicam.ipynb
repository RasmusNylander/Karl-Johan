{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from create_dataloader import make_dataloaders\n",
    "from medcam import medcam\n",
    "\n",
    "from model_picker import ModelType, get_model\n",
    "from monai.data.nifti_writer import nib\n",
    "from tqdm import trange"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "MODELS_ROOT = \"./models\"\n",
    "DATA_PATH = \"./datasets/sorted_downscaled\"\n",
    "BATCH_SIZE = 1\n",
    "assert BATCH_SIZE == 1\n",
    "\n",
    "model_type: ModelType = ModelType.ResNet18\n",
    "scale: float = 0.25\n",
    "assert scale in [0.25, 0.5, 1.0]\n",
    "\n",
    "model_string_id = f\"{model_type.name}_{str(int(scale*100)).zfill(3)}\"\n",
    "\n",
    "model_path = f\"{MODELS_ROOT}/{model_string_id}.pth\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "_, _, test_loader = make_dataloaders(num_workers=0, persistent_workers=False, data_path=DATA_PATH, batch_size=BATCH_SIZE, scale=scale)\n",
    "num_classes = len(test_loader.dataset.get_image_classes())\n",
    "\n",
    "model = get_model(model_type)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device)['net'], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from create_dataloader import Dataset\n",
    "\n",
    "def save_attention_map(attention_map: Tensor, path: str):\n",
    "\tfirst_channel = attention_map[0]\n",
    "\tfirst_channel = first_channel.numpy().transpose(1, 2, 0)\n",
    "\timage_nifti = nib.Nifti1Image(first_channel, affine=np.eye(4))\n",
    "\tnib.save(image_nifti, path)\n",
    "\n",
    "dataset: Dataset = test_loader.dataset\n",
    "\n",
    "models = [copy.copy(model)]\n",
    "medcam.inject(models[0], return_attention=True, layer=\"auto\", label=\"best\")\n",
    "for label in range(dataset.num_classes()):\n",
    "\tmedcam_model = copy.copy(model)\n",
    "\tmedcam_model = medcam.inject(medcam_model, return_attention=True, layer=\"auto\", label=label)\n",
    "\tmodels.append(medcam_model)\n",
    "\n",
    "\n",
    "image_output_root = f\"attention_maps/{model_string_id}/layer\"\n",
    "assert BATCH_SIZE == 1\n",
    "for image_id, (image_batch, batch_labels) in enumerate(test_loader):\n",
    "\timage_name = dataset.get_name_of_image(image_id)\n",
    "\timage_dir = f\"{image_output_root}/{image_name}\"\n",
    "\tif not os.path.exists(image_dir):\n",
    "\t\tos.makedirs(image_dir)\n",
    "\n",
    "\timage_batch = image_batch.to(device)\n",
    "\n",
    "\tprediction, attention_map_predicted_label = models[0](image_batch)\n",
    "\tprediction_label = prediction[0].argmax(dim=0).item()\n",
    "\tsave_attention_map(attention_map_predicted_label[0].detach().cpu(), f\"{image_dir}/{dataset.label_to_name(prediction_label)}\")\n",
    "\n",
    "\tcorrect_label = batch_labels[0].argmax(dim=0).item()\n",
    "\tif correct_label == prediction_label:\n",
    "\t\tcontinue\n",
    "\t_, attention_map_correct_label = models[correct_label + 1](image_batch)\n",
    "\tsave_attention_map(attention_map_correct_label[0].detach().cpu(), f\"{image_dir}/{dataset.label_to_name(correct_label)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_volume(attention_map):\n",
    "\tX, Y, Z = np.mgrid[0:28, 0:28, 0:28]\n",
    "\tvalues = attention_map\n",
    "\n",
    "\tfig = go.Figure(data=go.Volume(\n",
    "\t\tx=X.flatten(),\n",
    "\t\ty=Y.flatten(),\n",
    "\t\tz=Z.flatten(),\n",
    "\t\tvalue=values.flatten(),\n",
    "\t\tisomin=-0.1,\n",
    "\t\tisomax=0.8,\n",
    "\t\topacity=0.1,  # needs to be small to see through all surfaces\n",
    "\t\tsurface_count=21,  # needs to be a large number for good volume rendering\n",
    "\t\tcolorscale='RdBu'\n",
    "\t))\n",
    "\tfig.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_batch, batch_labels = next(test_loader.__iter__())\n",
    "model.eval()\n",
    "\n",
    "predictions, attention_maps = model(image_batch.to(device))\n",
    "\n",
    "\n",
    "for id, image in enumerate(image_batch):\n",
    "    first_channel: Tensor = image[0].cpu().numpy()\n",
    "    first_channel_dot_nii = nib.Nifti1Image(first_channel, affine=np.eye(4))\n",
    "    nib.save(first_channel_dot_nii, f\"attention_maps/image{id}\" + \".nii\")\n",
    "    plot_volume(first_channel)\n",
    "\n",
    "for id, attention_map in enumerate(attention_maps):\n",
    "    first_channel: Tensor = attention_map[0].cpu().numpy()\n",
    "    plot_volume(first_channel)\n",
    "\n",
    "print(\"I'm done, just so you know\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
